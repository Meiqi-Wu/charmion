{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the version of python and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a1cbb58d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './DATA/lish-moa/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(data_dir+'train_features.csv', index_col='sig_id')\n",
    "y = pd.read_csv(data_dir+'train_targets_scored.csv', index_col='sig_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 875)\n",
      "(23814, 206)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Number of NA in X, and y\n",
    "print(X.isnull().sum().sum())\n",
    "print(y.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# percentage of 1's in each column of y\n",
    "one_perc = y.apply(lambda x: x.sum()/len(y))\n",
    "plt.figure()\n",
    "plt.hist(one_perc, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp_type', 'cp_dose']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical columns\n",
    "col_cat = [col for col in X.columns if X[col].dtype == 'object']\n",
    "col_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trt_cp         21948\n",
       "ctl_vehicle     1866\n",
       "Name: cp_type, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.cp_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D1    12147\n",
       "D2    11667\n",
       "Name: cp_dose, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.cp_dose.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for cp_type and cp_dose\n",
    "X['cp_type'].replace({'trt_cp':1., 'ctl_vehicle':0.}, inplace=True)\n",
    "X['cp_dose'].replace({'D1':1., 'D2':0.}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training set and test set\n",
    "ids = X.index.values.copy()\n",
    "np.random.shuffle(ids)\n",
    "\n",
    "train_perc, test_perc = 0.8, 0.2\n",
    "train_id = ids[:round(len(ids)*train_perc)]\n",
    "test_id = ids[round(len(ids)*train_perc)+1:]\n",
    "\n",
    "X_train = X.loc[train_id]\n",
    "X_test = X.loc[test_id]\n",
    "\n",
    "y_train = y.loc[train_id]\n",
    "y_test = y.loc[test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "X_train_norm.columns = X_train.columns\n",
    "X_train_norm.index = X_train.index\n",
    "\n",
    "X_test_norm = pd.DataFrame(scaler.transform(X_test))\n",
    "X_test_norm.columns = X_test.columns\n",
    "X_test_norm.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_eed4f5eb5</th>\n",
       "      <td>-3.451946</td>\n",
       "      <td>-1.236669</td>\n",
       "      <td>0.980918</td>\n",
       "      <td>-0.456171</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.427600</td>\n",
       "      <td>-1.182563</td>\n",
       "      <td>-0.524187</td>\n",
       "      <td>-0.299103</td>\n",
       "      <td>0.945605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375991</td>\n",
       "      <td>0.037446</td>\n",
       "      <td>-0.282627</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>0.308799</td>\n",
       "      <td>1.054493</td>\n",
       "      <td>0.141999</td>\n",
       "      <td>0.306620</td>\n",
       "      <td>0.225334</td>\n",
       "      <td>-0.099044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_528f47dac</th>\n",
       "      <td>0.289692</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.980918</td>\n",
       "      <td>0.450424</td>\n",
       "      <td>-0.319481</td>\n",
       "      <td>-1.396536</td>\n",
       "      <td>-0.005718</td>\n",
       "      <td>-0.247520</td>\n",
       "      <td>3.341033</td>\n",
       "      <td>-0.484051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721413</td>\n",
       "      <td>0.594174</td>\n",
       "      <td>0.488883</td>\n",
       "      <td>0.341703</td>\n",
       "      <td>0.586436</td>\n",
       "      <td>-0.182267</td>\n",
       "      <td>0.546444</td>\n",
       "      <td>0.400113</td>\n",
       "      <td>0.337062</td>\n",
       "      <td>-0.275528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_f706afa88</th>\n",
       "      <td>0.289692</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.980918</td>\n",
       "      <td>-1.099553</td>\n",
       "      <td>-0.396522</td>\n",
       "      <td>0.778984</td>\n",
       "      <td>0.962121</td>\n",
       "      <td>-1.001836</td>\n",
       "      <td>-0.126575</td>\n",
       "      <td>-0.266299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087900</td>\n",
       "      <td>0.444295</td>\n",
       "      <td>0.397154</td>\n",
       "      <td>0.733476</td>\n",
       "      <td>0.023046</td>\n",
       "      <td>-0.501745</td>\n",
       "      <td>0.458904</td>\n",
       "      <td>0.297883</td>\n",
       "      <td>-0.976632</td>\n",
       "      <td>-0.523066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_1bb6de988</th>\n",
       "      <td>0.289692</td>\n",
       "      <td>-1.236669</td>\n",
       "      <td>0.980918</td>\n",
       "      <td>0.036681</td>\n",
       "      <td>0.470222</td>\n",
       "      <td>-0.214747</td>\n",
       "      <td>-0.247864</td>\n",
       "      <td>-0.645399</td>\n",
       "      <td>0.058925</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867269</td>\n",
       "      <td>0.825751</td>\n",
       "      <td>0.473814</td>\n",
       "      <td>0.355106</td>\n",
       "      <td>0.348301</td>\n",
       "      <td>0.526270</td>\n",
       "      <td>0.141260</td>\n",
       "      <td>0.030956</td>\n",
       "      <td>0.190197</td>\n",
       "      <td>0.451120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_a1c138776</th>\n",
       "      <td>0.289692</td>\n",
       "      <td>-1.236669</td>\n",
       "      <td>0.980918</td>\n",
       "      <td>2.208361</td>\n",
       "      <td>1.993362</td>\n",
       "      <td>-0.351596</td>\n",
       "      <td>2.984833</td>\n",
       "      <td>0.780252</td>\n",
       "      <td>-0.034757</td>\n",
       "      <td>0.413108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.524355</td>\n",
       "      <td>0.430530</td>\n",
       "      <td>0.463650</td>\n",
       "      <td>0.653685</td>\n",
       "      <td>-0.315908</td>\n",
       "      <td>-0.252784</td>\n",
       "      <td>0.071061</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.341108</td>\n",
       "      <td>0.516565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 875 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cp_type   cp_time   cp_dose       g-0       g-1       g-2  \\\n",
       "sig_id                                                                     \n",
       "id_eed4f5eb5 -3.451946 -1.236669  0.980918 -0.456171  0.005873  0.427600   \n",
       "id_528f47dac  0.289692  0.000195  0.980918  0.450424 -0.319481 -1.396536   \n",
       "id_f706afa88  0.289692  0.000195  0.980918 -1.099553 -0.396522  0.778984   \n",
       "id_1bb6de988  0.289692 -1.236669  0.980918  0.036681  0.470222 -0.214747   \n",
       "id_a1c138776  0.289692 -1.236669  0.980918  2.208361  1.993362 -0.351596   \n",
       "\n",
       "                   g-3       g-4       g-5       g-6  ...      c-90      c-91  \\\n",
       "sig_id                                                ...                       \n",
       "id_eed4f5eb5 -1.182563 -0.524187 -0.299103  0.945605  ...  0.375991  0.037446   \n",
       "id_528f47dac -0.005718 -0.247520  3.341033 -0.484051  ...  0.721413  0.594174   \n",
       "id_f706afa88  0.962121 -1.001836 -0.126575 -0.266299  ... -0.087900  0.444295   \n",
       "id_1bb6de988 -0.247864 -0.645399  0.058925  0.002735  ...  0.867269  0.825751   \n",
       "id_a1c138776  2.984833  0.780252 -0.034757  0.413108  ... -0.524355  0.430530   \n",
       "\n",
       "                  c-92      c-93      c-94      c-95      c-96      c-97  \\\n",
       "sig_id                                                                     \n",
       "id_eed4f5eb5 -0.282627  0.153964  0.308799  1.054493  0.141999  0.306620   \n",
       "id_528f47dac  0.488883  0.341703  0.586436 -0.182267  0.546444  0.400113   \n",
       "id_f706afa88  0.397154  0.733476  0.023046 -0.501745  0.458904  0.297883   \n",
       "id_1bb6de988  0.473814  0.355106  0.348301  0.526270  0.141260  0.030956   \n",
       "id_a1c138776  0.463650  0.653685 -0.315908 -0.252784  0.071061  0.000940   \n",
       "\n",
       "                  c-98      c-99  \n",
       "sig_id                            \n",
       "id_eed4f5eb5  0.225334 -0.099044  \n",
       "id_528f47dac  0.337062 -0.275528  \n",
       "id_f706afa88 -0.976632 -0.523066  \n",
       "id_1bb6de988  0.190197  0.451120  \n",
       "id_a1c138776  0.341108  0.516565  \n",
       "\n",
       "[5 rows x 875 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    '''\n",
    "    A block of a fully-connected layer with relu activation and dropout.\n",
    "    '''\n",
    "    def __init__(self, input_size, output_size, dropout_ratio):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        return F.relu(x)\n",
    "    \n",
    "class DenseNet(nn.Module):\n",
    "    '''\n",
    "    A few fully-connected layers, with sigmoid activation at the output layer.\n",
    "    '''\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        layer_size = [input_size] + hidden_size + [output_size]\n",
    "        for i in range(len(layer_size)-2):\n",
    "            self.layers.append(DenseBlock(layer_size[i], layer_size[i+1], dropout[i]))\n",
    "        self.layers.append(nn.Linear(layer_size[-2], layer_size[-1]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return F.sigmoid(x)\n",
    "    \n",
    "    def regular_loss(self, L1, L2):\n",
    "        l1, l2 = 0, 0\n",
    "        for layer in self.layers[:-1]:\n",
    "            w = layer.linear.weight.data\n",
    "            l1 += torch.sum(w.abs())\n",
    "            l2 += torch.sum(torch.mul(w,w))\n",
    "            \n",
    "        w = self.layers[-1].weight.data\n",
    "        l1 += torch.sum(w.abs())\n",
    "        l2 += torch.sum(torch.mul(w,w))\n",
    "        return L1*l1 + L2*l2\n",
    "       \n",
    "        \n",
    "class Model(object):\n",
    "    '''\n",
    "    The Model class.\n",
    "    '''\n",
    "    def __init__(self, net):\n",
    "        super(Model, self).__init__()\n",
    "        self.net = net\n",
    "        \n",
    "\n",
    "    def fit(self, X, y, epoch, lr, batch_size, L2, pos_weight, verbose=True):\n",
    "        \n",
    "        n_samples = len(X)\n",
    "        if type(X)!=np.ndarray:\n",
    "            X = X.values\n",
    "            y = y.values\n",
    "            \n",
    "        optimizer = optim.Adam(self.net.parameters(), lr = lr, weight_decay=L2)    \n",
    "        criterian = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(pos_weight))\n",
    "        \n",
    "        for e in range(epoch):\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                X_batch = X[i:min(i+batch_size, n_samples)]\n",
    "                y_target = y[i:min(i+batch_size, n_samples)]\n",
    "                X_batch = torch.from_numpy(X_batch).float()\n",
    "                y_target = torch.from_numpy(y_target).float()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                y_prob = self.net(X_batch)\n",
    "                \n",
    "                y_prob = y_prob.view(-1,1)\n",
    "                y_target = y_target.view(-1,1)\n",
    "            \n",
    "                loss = criterian(y_prob, y_target)\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "#                 gradient = self.net.layers[0].linear.weight.grad\n",
    "#                 print(torch.min(gradient), torch.max(gradient))\n",
    "                \n",
    "#                 if (gradient != gradient).any():\n",
    "#                     print('gradient')\n",
    "#                     print(gradient)\n",
    "                        \n",
    "                optimizer.step()\n",
    "                \n",
    "                if verbose:\n",
    "                    if i%(30*batch_size)==0:\n",
    "                        print(f\"Epoch [{e+1}, {i}] : loss {loss}\")       \n",
    "    \n",
    "    def predict(self, X):\n",
    "        prop = self.predict_prop(X)\n",
    "        res = (prop>0.5)*1\n",
    "        return res\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        if type(X)==pandas.core.frame.DataFrame:\n",
    "            X = torch.from_numpy(X.values).float()\n",
    "        elif type(X)== np.ndarray:\n",
    "            X = torch.from_numpy(X).float()\n",
    "        \n",
    "        output = self.net(X)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1, 0] : loss 1.0005818605422974\n",
      "Epoch [1, 3840] : loss 0.9951006770133972\n",
      "Epoch [1, 7680] : loss 0.9878619313240051\n",
      "Epoch [1, 11520] : loss 0.9844739437103271\n",
      "Epoch [1, 15360] : loss 0.9790265560150146\n",
      "Epoch [2, 0] : loss 0.9646669626235962\n",
      "Epoch [2, 3840] : loss 0.9639638066291809\n",
      "Epoch [2, 7680] : loss 0.9582882523536682\n",
      "Epoch [2, 11520] : loss 0.9549391865730286\n",
      "Epoch [2, 15360] : loss 0.950466513633728\n",
      "Epoch [3, 0] : loss 0.934808075428009\n",
      "Epoch [3, 3840] : loss 0.9348779916763306\n",
      "Epoch [3, 7680] : loss 0.9287047386169434\n",
      "Epoch [3, 11520] : loss 0.9224653244018555\n",
      "Epoch [3, 15360] : loss 0.916737973690033\n",
      "Epoch [4, 0] : loss 0.9005664587020874\n",
      "Epoch [4, 3840] : loss 0.8995251059532166\n",
      "Epoch [4, 7680] : loss 0.8929322361946106\n",
      "Epoch [4, 11520] : loss 0.8808804154396057\n",
      "Epoch [4, 15360] : loss 0.8745929598808289\n",
      "Epoch [5, 0] : loss 0.8601639866828918\n",
      "Epoch [5, 3840] : loss 0.8614380359649658\n",
      "Epoch [5, 7680] : loss 0.8559719920158386\n",
      "Epoch [5, 11520] : loss 0.8418405652046204\n",
      "Epoch [5, 15360] : loss 0.8386679887771606\n",
      "Epoch [6, 0] : loss 0.828944981098175\n",
      "Epoch [6, 3840] : loss 0.8341671824455261\n",
      "Epoch [6, 7680] : loss 0.8310238122940063\n",
      "Epoch [6, 11520] : loss 0.8186716437339783\n",
      "Epoch [6, 15360] : loss 0.8172903656959534\n",
      "Epoch [7, 0] : loss 0.8111310005187988\n",
      "Epoch [7, 3840] : loss 0.8189679384231567\n",
      "Epoch [7, 7680] : loss 0.8164277076721191\n",
      "Epoch [7, 11520] : loss 0.8055674433708191\n",
      "Epoch [7, 15360] : loss 0.8055515289306641\n",
      "Epoch [8, 0] : loss 0.8014185428619385\n",
      "Epoch [8, 3840] : loss 0.809884250164032\n",
      "Epoch [8, 7680] : loss 0.8078770041465759\n",
      "Epoch [8, 11520] : loss 0.7984021902084351\n",
      "Epoch [8, 15360] : loss 0.7987539172172546\n",
      "Epoch [9, 0] : loss 0.7952877283096313\n",
      "Epoch [9, 3840] : loss 0.8047827482223511\n",
      "Epoch [9, 7680] : loss 0.8027346134185791\n",
      "Epoch [9, 11520] : loss 0.7937421202659607\n",
      "Epoch [9, 15360] : loss 0.7941091060638428\n",
      "Epoch [10, 0] : loss 0.7916458249092102\n",
      "Epoch [10, 3840] : loss 0.8012961149215698\n",
      "Epoch [10, 7680] : loss 0.7986728549003601\n",
      "Epoch [10, 11520] : loss 0.790353000164032\n",
      "Epoch [10, 15360] : loss 0.7909201383590698\n"
     ]
    }
   ],
   "source": [
    "params_net = {'input_size': X_train_norm.shape[1],\n",
    "             'hidden_size': [1024],\n",
    "             'output_size': y_train.shape[1],\n",
    "             'dropout': [0.1, 0.1]}\n",
    "\n",
    "params_fit = {'X':X_train_norm,\n",
    "             'y': y_train,\n",
    "             'epoch': 10,\n",
    "             'lr': 1e-5,\n",
    "             'batch_size':128,\n",
    "             'L2': 0.005,\n",
    "             'pos_weight':20,\n",
    "             'verbose':True}\n",
    "\n",
    "net = DenseNet(**params_net)\n",
    "model = Model(net)\n",
    "model.fit(**params_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ModelTest(nn.Module):\n",
    "#     '''\n",
    "#     A block of a fully-connected layer with relu activation and dropout.\n",
    "#     '''\n",
    "#     def __init__(self, input_size, hidden_size_1, hidden_size_2, output_size):\n",
    "#         super(ModelTest, self).__init__()\n",
    "#         self.linear1 = nn.Linear(input_size, hidden_size_1)\n",
    "#         self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "#         self.linear3 = nn.Linear(hidden_size_2, output_size)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.linear1(x)\n",
    "#         out = self.linear2(out)\n",
    "#         out = self.linear3(out)\n",
    "#         return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
