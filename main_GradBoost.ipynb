{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import log_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import wait, ALL_COMPLETED, as_completed\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_dir = './DATA/lish-moa/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Table of Contents   \n",
    "1. Load the dataset  \n",
    "2. Preprocessing   \n",
    "3. Models : Binary Relevance (Gradient Boost)  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(data_dir+'train_features.csv', index_col='sig_id')\n",
    "y = pd.read_csv(data_dir+'train_targets_scored.csv', index_col='sig_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for cp_type and cp_dose\n",
    "X['cp_type'].replace({'trt_cp':1., 'ctl_vehicle':0.}, inplace=True)\n",
    "X['cp_dose'].replace({'D1':1., 'D2':0.}, inplace=True)\n",
    "\n",
    "# split into training set and test set\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "\n",
    "ids = X.index.values.copy()\n",
    "np.random.shuffle(ids)\n",
    "\n",
    "train_perc, test_perc = 0.85, 0.2\n",
    "train_id = ids[:round(len(ids)*train_perc)]\n",
    "test_id = ids[round(len(ids)*train_perc):]\n",
    "\n",
    "X_train = X.loc[train_id]\n",
    "X_test = X.loc[test_id]\n",
    "\n",
    "y_train = y.loc[train_id]\n",
    "y_test = y.loc[test_id]\n",
    "\n",
    "# normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "X_train_norm.columns = X_train.columns\n",
    "X_train_norm.index = X_train.index\n",
    "\n",
    "X_test_norm = pd.DataFrame(scaler.transform(X_test))\n",
    "X_test_norm.columns = X_test.columns\n",
    "X_test_norm.index = X_test.index\n",
    "\n",
    "pca = PCA(n_components=700)\n",
    "X_train_pca = pd.DataFrame(pca.fit_transform(X_train_norm))\n",
    "X_train_pca.index = X_train.index\n",
    "\n",
    "X_test_pca = pd.DataFrame(pca.transform(X_test_norm))\n",
    "X_test_pca.index = X_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models : Binary Relevance (Gradient Boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 1 \n",
      "Start 2 \n",
      "Start 3 \n",
      "Start 4 \n",
      "--- Completed 1, 5-alpha_reductase_inhibitor, 5.7792 mins ---\n",
      "Start 5 5-alpha_reductase_inhibitor\n",
      "\n",
      "--- Completed 2, acat_inhibitor, 6.9880 mins ---\n",
      "Start 6 acat_inhibitor\n",
      "\n",
      "--- Completed 3, 11-beta-hsd1_inhibitor, 9.0095 mins ---\n",
      "Start 7 11-beta-hsd1_inhibitor\n",
      "\n",
      "--- Completed 4, acetylcholine_receptor_agonist, 10.2732 mins ---\n",
      "Start 8 acetylcholine_receptor_agonist\n",
      "\n",
      "--- Completed 5, acetylcholine_receptor_antagonist, 10.3052 mins ---\n",
      "Start 9 acetylcholine_receptor_antagonist\n",
      "\n",
      "--- Completed 6, acetylcholinesterase_inhibitor, 10.3412 mins ---\n",
      "Start 10 acetylcholinesterase_inhibitor\n",
      "\n",
      "--- Completed 7, adenosine_receptor_agonist, 9.5530 mins ---\n",
      "Start 11 adenosine_receptor_agonist\n",
      "\n",
      "--- Completed 8, adenosine_receptor_antagonist, 10.2425 mins ---\n",
      "Start 12 adenosine_receptor_antagonist\n",
      "\n",
      "--- Completed 9, adenylyl_cyclase_activator, 5.0440 mins ---\n",
      "Start 13 adenylyl_cyclase_activator\n",
      "\n",
      "--- Completed 10, aldehyde_dehydrogenase_inhibitor, 3.7099 mins ---\n",
      "Start 14 \n",
      "aldehyde_dehydrogenase_inhibitor\n",
      "--- Completed 11, adrenergic_receptor_agonist, 10.0553 mins ---\n",
      "Start 15 adrenergic_receptor_agonist\n",
      "\n",
      "--- Completed 12, akt_inhibitor, 7.8729 mins ---\n",
      "Start 16 akt_inhibitor\n",
      "\n",
      "--- Completed 13, adrenergic_receptor_antagonist, 10.0018 mins ---\n",
      "Start 17 adrenergic_receptor_antagonist\n",
      "\n",
      "--- Completed 14, alk_inhibitor, 6.6577 mins ---\n",
      "Start 18 alk_inhibitor\n",
      "\n",
      "--- Completed 15, ampk_activator, 4.6174 mins ---\n",
      "Start 19 ampk_activator\n",
      "\n",
      "--- Completed 16, analgesic, 4.6240 mins ---\n",
      "Start 20 analgesic\n",
      "\n",
      "--- Completed 17, androgen_receptor_agonist, 9.8732 mins ---\n",
      "Start 21 androgen_receptor_agonist\n",
      "\n",
      "--- Completed 18, androgen_receptor_antagonist, 9.9738 mins ---\n",
      "Start 22 androgen_receptor_antagonist\n",
      "\n",
      "--- Completed 19, anesthetic_-_local, 9.8910 mins ---\n",
      "Start 23 anesthetic_-_local\n",
      "\n",
      "--- Completed 20, angiogenesis_inhibitor, 9.8096 mins ---\n",
      "Start 24 angiogenesis_inhibitor\n",
      "\n",
      "--- Completed 21, angiotensin_receptor_antagonist, 6.5981 mins ---\n",
      "Start 25 angiotensin_receptor_antagonist\n",
      "\n",
      "--- Completed 22, antiarrhythmic, 4.9829 mins ---\n",
      "Start 26 antiarrhythmic\n",
      "\n",
      "--- Completed 23, anticonvulsant, 4.4585 mins ---\n",
      "Start 27 anticonvulsant\n",
      "\n",
      "--- Completed 24, anti-inflammatory, 8.8266 mins ---\n",
      "Start 28 anti-inflammatory\n",
      "\n",
      "--- Completed 25, antibiotic, 8.3761 mins ---\n",
      "Start 29 antibiotic\n",
      "\n",
      "--- Completed 26, antifungal, 6.0861 mins ---\n",
      "Start 30 antifungal\n",
      "\n",
      "--- Completed 27, antihistamine, 6.1583 mins ---\n",
      "Start 31 antihistamine\n",
      "\n",
      "--- Completed 28, antimalarial, 6.2692 mins ---\n",
      "Start 32 antimalarial\n",
      "\n",
      "--- Completed 29, antiprotozoal, 7.7563 mins ---\n",
      "Start 33 antiprotozoal\n",
      "\n",
      "--- Completed 30, antioxidant, 9.9514 mins ---\n",
      "Start 34 antioxidant\n",
      "\n",
      "--- Completed 31, antiviral, 6.1261 mins ---\n",
      "Start 35 antiviral\n",
      "\n",
      "--- Completed 32, apoptosis_stimulant, 7.2650 mins ---\n",
      "Start 36 apoptosis_stimulant\n",
      "\n",
      "--- Completed 33, atp-sensitive_potassium_channel_antagonist, 4.6677 mins ---\n",
      "Start 37 atp-sensitive_potassium_channel_antagonist\n",
      "\n",
      "--- Completed 34, atm_kinase_inhibitor, 5.9151 mins ---\n",
      "Start 38 atm_kinase_inhibitor\n",
      "\n",
      "--- Completed 35, atp_synthase_inhibitor, 4.2879 mins ---\n",
      "Start 39 atp_synthase_inhibitor\n",
      "\n",
      "--- Completed 36, aromatase_inhibitor, 9.6315 mins ---\n",
      "Start 40 aromatase_inhibitor\n",
      "\n",
      "--- Completed 37, atr_kinase_inhibitor, 5.0248 mins ---\n",
      "Start 41 \n",
      "atr_kinase_inhibitor\n",
      "--- Completed 38, atpase_inhibitor, 10.0728 mins ---\n",
      "Start 42 atpase_inhibitor\n",
      "\n",
      "--- Completed 39, autotaxin_inhibitor, 6.5550 mins ---\n",
      "Start 43 autotaxin_inhibitor\n",
      "\n",
      "--- Completed 40, aurora_kinase_inhibitor, 9.9415 mins ---\n",
      "Start 44 aurora_kinase_inhibitor\n",
      "\n",
      "--- Completed 41, bacterial_30s_ribosomal_subunit_inhibitor, 8.6489 mins ---\n",
      "Start 45 bacterial_30s_ribosomal_subunit_inhibitor\n",
      "\n",
      "--- Completed 42, bacterial_antifolate, 7.9525 mins ---\n",
      "Start 46 bacterial_antifolate\n",
      "\n",
      "--- Completed 43, bacterial_50s_ribosomal_subunit_inhibitor, 10.0272 mins ---\n",
      "Start 47 bacterial_50s_ribosomal_subunit_inhibitor\n",
      "\n",
      "--- Completed 44, bacterial_cell_wall_synthesis_inhibitor, 9.9584 mins ---\n",
      "Start 48 bacterial_cell_wall_synthesis_inhibitor\n",
      "\n",
      "--- Completed 45, bacterial_membrane_integrity_inhibitor, 3.5588 mins ---\n",
      "Start 49 bacterial_membrane_integrity_inhibitor\n",
      "\n",
      "--- Completed 46, bacterial_dna_gyrase_inhibitor, 9.8675 mins ---\n",
      "Start 50 bacterial_dna_gyrase_inhibitor\n",
      "\n",
      "--- Completed 47, bcl_inhibitor, 5.8481 mins ---\n",
      "Start 51 bcl_inhibitor\n",
      "\n",
      "--- Completed 48, bacterial_dna_inhibitor, 9.7198 mins ---\n",
      "Start 52 bacterial_dna_inhibitor\n",
      "\n",
      "--- Completed 49, bcr-abl_inhibitor, 7.9396 mins ---\n",
      "Start 53 bcr-abl_inhibitor\n",
      "\n",
      "--- Completed 50, beta_amyloid_inhibitor, 6.0523 mins ---\n",
      "Start 54 beta_amyloid_inhibitor\n",
      "\n",
      "--- Completed 51, benzodiazepine_receptor_agonist, 9.7155 mins ---\n",
      "Start 55 benzodiazepine_receptor_agonist\n",
      "\n",
      "--- Completed 52, bromodomain_inhibitor, 9.6482 mins ---\n",
      "Start 56 bromodomain_inhibitor\n",
      "\n",
      "--- Completed 53, btk_inhibitor, 6.8527 mins ---\n",
      "Start 57 btk_inhibitor\n",
      "\n",
      "--- Completed 54, calcineurin_inhibitor, 7.0767 mins ---\n",
      "Start 58 calcineurin_inhibitor\n",
      "\n",
      "--- Completed 55, calcium_channel_blocker, 9.8502 mins ---\n",
      "Start 59 calcium_channel_blocker\n",
      "\n",
      "--- Completed 56, cannabinoid_receptor_agonist, 9.5756 mins ---\n",
      "Start 60 cannabinoid_receptor_agonist\n",
      "\n",
      "--- Completed 57, cannabinoid_receptor_antagonist, 9.3625 mins ---\n",
      "Start 61 cannabinoid_receptor_antagonist\n",
      "\n",
      "--- Completed 58, carbonic_anhydrase_inhibitor, 7.5922 mins ---\n",
      "Start 62 carbonic_anhydrase_inhibitor\n",
      "\n",
      "--- Completed 59, casein_kinase_inhibitor, 7.0296 mins ---\n",
      "Start 63 casein_kinase_inhibitor\n",
      "\n",
      "--- Completed 60, caspase_activator, 5.5322 mins ---\n",
      "Start 64 caspase_activator\n",
      "\n",
      "--- Completed 61, catechol_o_methyltransferase_inhibitor, 6.1004 mins ---\n",
      "Start 65 catechol_o_methyltransferase_inhibitor\n",
      "\n",
      "--- Completed 62, cck_receptor_antagonist, 6.5016 mins ---\n",
      "Start 66 cck_receptor_antagonist\n",
      "\n",
      "--- Completed 63, cc_chemokine_receptor_antagonist, 9.9305 mins ---\n",
      "Start 67 cc_chemokine_receptor_antagonist\n",
      "\n",
      "--- Completed 64, chk_inhibitor, 5.6266 mins ---\n",
      "Start 68 chk_inhibitor\n",
      "\n",
      "--- Completed 65, cdk_inhibitor, 10.0071 mins ---\n",
      "Start 69 cdk_inhibitor\n",
      "\n",
      "--- Completed 66, chelating_agent, 9.4826 mins ---\n",
      "Start 70 chelating_agent\n",
      "\n",
      "--- Completed 67, chloride_channel_blocker, 9.8264 mins ---\n",
      "Start 71 chloride_channel_blocker\n",
      "\n",
      "--- Completed 68, coagulation_factor_inhibitor, 6.0740 mins ---\n",
      "Start 72 coagulation_factor_inhibitor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weight_ratio = 0.7\n",
    "n_estimators = 50\n",
    "max_depth = 3\n",
    "early_stopping_rounds = 2\n",
    "\n",
    "current = 0\n",
    "start = 0\n",
    "model_dic_gb = {}\n",
    "\n",
    "def calculate_model(i, y):\n",
    "    global model_dic_gb\n",
    "    global current\n",
    "    global start\n",
    "    \n",
    "    start += 1\n",
    "    start_time = time.process_time()\n",
    "    print(\"Start \" + str(start) + \" \")\n",
    "\n",
    "    num_train = X_train.shape[0]\n",
    "    X = X_train.values[:round(num_train*0.85)].copy() # train\n",
    "    X1 = X_train.values[round(num_train*0.85):].copy() # validation\n",
    "    y1 = y[round(num_train*0.85):] # y validatation\n",
    "    y = y[:round(num_train*0.85)] # y train\n",
    "    X2 = X_test.values\n",
    "    # class_weight for each target column\n",
    "    scale_pos_weight = min(round(len(y)/sum(y)-1)*weight_ratio, 8000)\n",
    "    gbc = XGBClassifier(n_estimators = n_estimators,\n",
    "                        max_depth = max_depth,\n",
    "                        scale_pos_weight = scale_pos_weight,\n",
    "                        n_jobs = -1,\n",
    "                        random_state=100)\n",
    "    eval_set = [(X1, y1)]\n",
    "    gbc.fit(X, y, eval_set=eval_set, eval_metric='logloss', early_stopping_rounds = early_stopping_rounds, verbose=False);\n",
    "    \n",
    "    model_dic_gb[i] = gbc\n",
    "    current += 1\n",
    "    print(\"--- Completed %s, %s, %.4f mins ---\" % (current, i, (time.process_time() - start_time) / 60))\n",
    "    return i\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as t:\n",
    "    futures = []\n",
    "    for i, y in y_train.iteritems():\n",
    "        futures.append(t.submit(calculate_model, i, y))\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        print(future.result())\n",
    "    \n",
    "print(model_dic_gb.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = pd.DataFrame([], columns=y_train.columns)\n",
    "y_test_predict = pd.DataFrame([], columns=y_train.columns)\n",
    "X = X_train.values\n",
    "X2 = X_test.values\n",
    "\n",
    "for i, gbc in tqdm(model_dic_gb.items()):\n",
    "    y_train_predict[i] = gbc.predict(X)\n",
    "    y_test_predict[i] = gbc.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ratio: 0.73  n_estimators: 75  max_depth: 4  early_stopping_rounds: 2\n",
      "Precision: \n",
      "0.9923206751054853\n",
      "Recall: \n",
      "1.0\n",
      "F1: \n",
      "0.9961455377186667\n",
      "\n",
      "Precision: \n",
      "0.7435684647302905\n",
      "Recall: \n",
      "0.2636069432185937\n",
      "F1: \n",
      "0.3892267593397046\n",
      "\n",
      "11759\n",
      "11850\n",
      "\n",
      "3399\n",
      "1205\n"
     ]
    }
   ],
   "source": [
    "# binary relavance\n",
    "print('weight_ratio:',weight_ratio, ' n_estimators:',n_estimators, ' max_depth:', max_depth, ' early_stopping_rounds:', early_stopping_rounds)\n",
    "print('Precision: ')\n",
    "print(precision_score(y_train, y_train_predict))\n",
    "print('Recall: ')\n",
    "print(recall_score(y_train, y_train_predict))\n",
    "print('F1: ')\n",
    "print(f1_score(y_train, y_train_predict))\n",
    "print()\n",
    "print('Precision: ')\n",
    "print(precision_score(y_test, y_test_predict))\n",
    "print('Recall: ')\n",
    "print(recall_score(y_test, y_test_predict))\n",
    "print('F1: ')\n",
    "print(f1_score(y_test, y_test_predict))\n",
    "print()\n",
    "print(y_train.sum().sum())\n",
    "print(y_train_predict.sum().sum())\n",
    "print()\n",
    "print(y_test.sum().sum())\n",
    "print(y_test_predict.sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search with cross-validatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 1 Start 2 \n",
      "\n",
      "Start 3 \n",
      "Start 4 \n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "\n",
    "current = 0\n",
    "start = 0\n",
    "best_model = {}\n",
    "best_params = {}\n",
    "X = X_train_pca.values\n",
    "def search_model(i, col_name, y):\n",
    "    global best_model\n",
    "    global best_params\n",
    "    global current\n",
    "    global start\n",
    "    \n",
    "    start += 1\n",
    "    start_time = time.process_time()\n",
    "    print(\"Start \" + str(start) + \" \")\n",
    "    \n",
    "#     pca = PCA()\n",
    "    gbc = XGBClassifier(learning_rate=0.008, n_jobs=-1, random_state = 90)\n",
    "#     pipe = Pipeline([('pca', pca), ('xgb', gbc)])\n",
    "\n",
    "    ratio = round(len(y)/sum(y)-1)\n",
    "#     tuned_params = {\n",
    "#         'pca__n_components':[500, 600, 700],\n",
    "#         'xgb__scale_pos_weight':[round(weight_ratio*ratio) for weight_ratio in [0.64, 0.66, 0.68, 0.7]],\n",
    "#         'xgb__max_depth': [3,4,5],\n",
    "#         'xgb__gamma':[0.5, 1, 2, 4],\n",
    "#         'xgb__colsample_bytree':[0.6, 0.8, 1],\n",
    "#         'xgb__min_child_weight': [1, 5]\n",
    "#     }\n",
    "    tuned_params = {\n",
    "        'scale_pos_weight':[round(weight_ratio*ratio) for weight_ratio in [0.64, 0.66, 0.68, 0.7]],\n",
    "        'max_depth': [3,4,5],\n",
    "        'gamma':[0.5, 1, 2, 4],\n",
    "        'colsample_bytree':[0.6, 0.8, 1],\n",
    "        'min_child_weight': [1, 5]\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 200)\n",
    "    search = RandomizedSearchCV(estimator = gbc, param_distributions=tuned_params,\n",
    "                               cv = skf.split(X, y), scoring='neg_log_loss', n_iter=60,\n",
    "                               random_state=100)\n",
    "    search.fit(X, y)\n",
    "    best_model[col_name] = search.best_estimator_\n",
    "    best_params[col_name] = search.best_params_\n",
    "    \n",
    "    joblib.dump(best_model[col_name], f'./TrainedModels/GradBoost/gbc_{i}.joblib')\n",
    "    current += 1\n",
    "    print(\"--- Completed %s, %s, %.4f mins ---\" % (current, col_name, (time.process_time() - start_time) / 60))\n",
    "    \n",
    "with ThreadPoolExecutor(max_workers=4) as t:\n",
    "    futures = []\n",
    "    for i, (col_name, y) in enumerate(y_train.iteritems()):\n",
    "        futures.append(t.submit(search_model, i, col_name, y))\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        print(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference - training\n",
    "y_train_pred = np.zeros(y_train.shape).astype('float')\n",
    "y_train_pred_proba = np.zeros(y_train.shape).astype('float')\n",
    "for i, col_name in tqdm(enumerate(y_train.columns)):\n",
    "    gbc = best_model.get(col_name, None)\n",
    "    if gbc!=None:\n",
    "        y_train_pred[:,i] = gbc.predict(X_train)\n",
    "        y_train_pred_proba[:,i] = gbc.predict_proba(X_train)[:,1]\n",
    "# overall log_loss\n",
    "print(log_loss(y_train.values.reshape(-1, 1), y_train_pred_proba.reshape(-1,1)))\n",
    "# overall precision\n",
    "print(precision_score(y_train.values.reshape(-1, 1), y_train_pred.reshape(-1,1)))\n",
    "# overall precision\n",
    "print(recall_score(y_train.values.reshape(-1, 1), y_train_pred.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference - test\n",
    "y_pred = np.zeros(y_test.shape).astype('float')\n",
    "y_pred_proba = np.zeros(y_test.shape).astype('float')\n",
    "for i, col_name in tqdm(enumerate(y_test.columns)):\n",
    "    rfc = best_rfc.get(col_name, None)\n",
    "    if rfc!=None:\n",
    "        y_pred[:,i] = rfc.predict(X_test)\n",
    "        y_pred_proba[:,i] = rfc.predict_proba(X_test)[:,1]\n",
    "# overall log_loss\n",
    "print(log_loss(y_test.values.reshape(-1, 1), y_pred_proba.reshape(-1,1)))\n",
    "# overall precision\n",
    "print(precision_score(y_test.values.reshape(-1, 1), y_pred.reshape(-1,1)))\n",
    "# overall precision\n",
    "print(recall_score(y_test.values.reshape(-1, 1), y_pred.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall, f1, for each column\n",
    "recall = np.zeros(y_train.shape[1])\n",
    "f1 = np.zeros(y_train.shape[1])\n",
    "for i in range(y_predict.shape[1]):\n",
    "    recall[i] = recall_score(y_test.values[:,i], y_pred[:,i])\n",
    "    f1[i] = f1_score(y_test.values[:,i], y_pred[:,i])\n",
    "    \n",
    "# best weight_ratio\n",
    "weight_ratio = np.ones(y_train.shape[1])*0.72\n",
    "for i, (col_name, y) in enumerate(y_train.iteritems()):\n",
    "    ratio[i] = round(len(y)/sum(y)-1)\n",
    "    param = best_params.get(col_name, None)\n",
    "    if param != None:\n",
    "        weight_ratio[i] = round(param['class_weight'][1]/ratio[i], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(weight_ratio)\n",
    "plt.plot(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_ratio[recall==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio[recall==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.read_csv(data_dir+'test_features.csv', index_col='sig_id')\n",
    "df_submit['cp_type'].replace({'trt_cp':1., 'ctl_vehicle':0.}, inplace=True)\n",
    "df_submit['cp_dose'].replace({'D1':1., 'D2':0.}, inplace=True)\n",
    "df_submit.head()\n",
    "# inference\n",
    "X_submit = df_submit.values\n",
    "y_submit_proba = pd.DataFrame([], columns=y_train.columns)\n",
    "for i, gbc in tqdm(model_dic_gb.items()):\n",
    "    y_predict_proba = gbc.predict_proba(X_submit)[:,1].reshape(-1,1)\n",
    "    y_submit_proba[i] = y_predict_proba\n",
    "    \n",
    "y_submit_proba = pd.DataFrame(y_submit_proba)\n",
    "y_submit_proba.index = df_submit.index\n",
    "y_submit_proba.head()\n",
    "y_submit_proba.to_csv('submission.csv', , float_format='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
